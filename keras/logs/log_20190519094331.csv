# Information,,,,
# Number of channels,1,,,
# Mini-batch size,10,,,
# Number of filters,128,,,
# Filter length,32,,,
# Regularization Coefficient,0.2,,,
# Pool size,128,,,
# Dropout rate,0.25,,,
# FC layer neurons,64,,,
# Learning rate,0.009,,,
# Pooling type,max,,,
# Optimizer,adam,,,
# Conv activation,relu,,,
# FC activation,relu,,,
# Output activation,softmax,,,
# Classifier,mlp,,,
,,,,
epoch,acc,loss,val_acc,val_loss
0,0.500000003,40.86877804,0.440000004,21.41847687
1,0.58000001,16.34235935,0.440000004,12.95975513
2,0.48000001,11.14636221,0.440000004,9.023833656
3,0.470000008,10.17777801,0.560000014,8.344633007
4,0.460000006,6.808879185,0.580000013,6.074815273
5,0.500000006,5.287000012,0.660000008,3.758955431
6,0.560000008,3.487808728,0.560000014,2.870503521
7,0.499999999,3.135973287,0.560000014,2.169750643
8,0.49000001,1.959125912,0.560000014,1.618381333
9,0.490000007,1.464550686,0.560000014,1.292643094
10,0.510000002,1.19656781,0.560000014,1.10869379
11,0.510000007,1.059259176,0.560000014,0.999097061
12,0.500000009,0.971303183,0.560000014,0.935295439
13,0.500000007,0.918504858,0.560000014,0.893858778
14,0.500000006,0.87980783,0.560000014,0.861137104
15,0.500000004,0.850613296,0.560000014,0.835689712
16,0.500000009,0.828157121,0.560000014,0.814396358
17,0.500000007,0.808378887,0.560000014,0.798024213
18,0.430000011,0.792171592,0.440000004,0.784190845
19,0.420000009,0.778859729,0.560000014,0.770968986
20,0.520000011,0.767488009,0.440000004,0.761559892
21,0.470000008,0.757465488,0.440000004,0.752574825
22,0.44000001,0.749298942,0.560000014,0.744468319
23,0.58000001,0.7416637,0.440000004,0.738371515
24,0.480000007,0.735820818,0.440000004,0.732720721
25,0.440000004,0.730082506,0.560000014,0.726685381
26,0.360000006,0.727159226,0.440000004,0.724053657
27,0.470000003,0.72182318,0.560000014,0.718647075
28,0.380000007,0.718500519,0.560000014,0.715682423
29,0.460000005,0.714865756,0.560000014,0.713121307
30,0.480000004,0.712625325,0.440000004,0.711173725
31,0.460000008,0.709829998,0.560000014,0.708176208
32,0.500000006,0.707879823,0.560000014,0.705609953
33,0.500000009,0.706292236,0.560000014,0.703366041
34,0.500000006,0.704841948,0.560000014,0.702208602
35,0.50000001,0.703192806,0.560000014,0.701236391
36,0.500000006,0.702423412,0.560000014,0.700007081
37,0.430000006,0.701055843,0.440000004,0.700364888
38,0.470000009,0.699926609,0.440000004,0.69946847
39,0.450000001,0.699120665,0.560000014,0.698498464
40,0.500000007,0.698394305,0.440000004,0.6981071
41,0.500000004,0.698151511,0.440000004,0.697741938
42,0.460000005,0.69745698,0.560000014,0.696649373
43,0.430000006,0.697116011,0.440000004,0.697271979
44,0.500000003,0.696290654,0.440000004,0.696556425
45,0.500000007,0.696501762,0.440000004,0.696803248
46,0.500000013,0.696131998,0.440000004,0.696312129
47,0.5,0.695304716,0.440000004,0.695359349
48,0.500000001,0.695380342,0.440000004,0.695509028
49,0.450000009,0.694752318,0.560000014,0.694509172
50,0.500000009,0.694729513,0.560000014,0.693852437
51,0.500000006,0.69451043,0.560000014,0.69334898
52,0.55,0.694490463,0.560000014,0.692930901
53,0.55,0.694130141,0.560000014,0.693388104
54,0.55,0.694330674,0.560000014,0.692920852
55,0.58,0.69464342,0.560000014,0.692999327
56,0.6,0.693796152,0.560000014,0.693638945
57,0.6,0.69386223,0.440000004,0.693963575
58,0.6,0.693915009,0.440000004,0.694127047
59,0.6,0.694092453,0.440000004,0.694708204
60,0.6,0.693764609,0.440000004,0.69424367
61,0.62,0.693474621,0.6,0.693369091
62,0.65,0.693868089,0.6,0.693232536
63,0.65,0.69348675,0.6,0.693120837
64,0.68,0.69350661,0.6,0.69267813
65,0.7,0.693388963,0.6,0.692969513
66,0.7,0.693567914,0.6,0.69255712
67,0.7,0.693735069,0.6,0.693550313
68,0.75,0.695683956,0.6,0.691779339
69,0.78,0.693559027,0.7,0.693019438
70,0.8,0.693678606,0.7,0.692622924
71,0.82,0.694051778,0.7,0.694332838
72,0.82,0.693466729,0.7,0.693658221
